# Асинхронный парсер PEP на базе фреймворка Scrapy.

##  **Описание**
Парсинг данных со страницы с общей информацией о PEP (https://peps.python.org/)
с переходом по внутренним ссылкам и сбором информации о каждом PEP.
Парсер собирает данные и сохраняет их в файлы формата csv в папку results.

## **Как апустить проект**
Выполните следующие команды в терминале:

1. Клонировать проект из репозитория:
```
git clone git@github.com:Kirill-kuz/scrapy_parser_pep.git
```
2. В корневой папке создайте виртуальное окружение и установите зависимости:
```
python -m venv venv
```
```
source venv/Scripts/activate
```
```
pip install -r requirements.txt 
```
3. Запустить парсер из командной строки в терминале:
```
scrapy crawl pep
```

## **Результат парсинга**
1. Первый файл - pep_ДатаВремя.csv - будет содержать список всех PEP с полями: number, name, status.

2. Второй файл - status_summary_ДатаВремя.csv - будет содержать сводку по всем статусам PEP,
найденых документов в каждом статусе. 
В последней строке в колонке Total выводится общее количество всех документов.
